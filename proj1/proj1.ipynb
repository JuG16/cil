{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def parse(row):\n",
    "    numbers = re.findall(r'\\d+', row[0])\n",
    "    numbers = list(map(int, numbers))\n",
    "    value = int(row[1])\n",
    "    return (numbers, value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    result = 1.0 / (1.0 + np.e**-z)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "firstrow = True\n",
    "X = np.zeros((1000,10000)) #movies, users\n",
    "with open('data_train.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        if not firstrow:\n",
    "            numbers, value = parse(row) #numbers is (columns, rows)\n",
    "            X[numbers[1]-1, numbers[0]-1] = value \n",
    "        else:\n",
    "            firstrow = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD MSE: 1.1574378043774212 STD: 1.15743575388\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#do simple SVD\n",
    "\n",
    "#maybe use these values for better analysis\n",
    "similarity_between_users = X * X.T #(X[i,j] how similar is user i to user j) \n",
    "similarity_between_movies = X.T * X #(X[i,j] how similar is movie i to movie j)\n",
    "\n",
    "U, D, V = svds(X, k=40)\n",
    "X_a = np.dot(np.dot(U, np.diag(D)), V)\n",
    "\n",
    "print ('SVD MSE: ' + str(rmse(X_a, X)) + \" STD: \" + str(np.std(X_a - X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "averageRatingPerMovie = X.sum(1)/(X != 0).sum(1) #(1000,1)\n",
    "\n",
    "#simple Prediction, no need to train anything...\n",
    "\n",
    "def predictRating_Baseline(movie,user):\n",
    "    averageRating = averageRatingPerMovie[movie]\n",
    "    ratingsByUser_indices = X[:,user] > 0\n",
    "    averageOffset = np.mean(averageRatingPerMovie[ratingsByUser_indices] - X[ratingsByUser_indices, user])\n",
    "    return averageRating + averageOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use this for Netflix\n",
    "def predictRating(movie, user):\n",
    "    #maybe do some feature transformation sigmoid\n",
    "    predict = np.dot(movieFeature[:, movie],userFeature [:, user])\n",
    "    if predict > 5:\n",
    "        predict = 5\n",
    "    else:\n",
    "        if predict < 1:\n",
    "            predict = 1\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for Netflix\n",
    "\n",
    "#params\n",
    "lrate = 0.001\n",
    "#K should be very small, is to reduce prior\n",
    "K = 0.02\n",
    "\n",
    "#works well if k is large\n",
    "def train_tikhonov(movie, user, feature, firstRound):\n",
    "    true_rating = X[movie, user]\n",
    "    if firstRound: \n",
    "        predicted_rating = predictRating_Baseline(movie,user)\n",
    "        err = (true_rating - predicted_rating)\n",
    "        #print(\"Predicted: \"+ str(predicted_rating) + \" True: \" + str(true_rating))\n",
    "    else:\n",
    "        predicted_rating = predictRating(movie,user)\n",
    "        err = (true_rating - predicted_rating)\n",
    "        #print(\"Predicted: \"+ str(predicted_rating) + \" True: \" + str(true_rating))\n",
    "    uv = userFeature[feature, user]\n",
    "    userFeature[feature, user] = uv + lrate * (err * movieFeature[feature, movie] - K * uv)\n",
    "    movieFeature[feature, movie] = movieFeature[feature, movie] + lrate * (err * uv - K * movieFeature[feature, movie])\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0\n",
      "Errors of feature 0: rmse 3.05399887438\n",
      "Errors of feature 1: rmse 2.92048493867\n",
      "Errors of feature 2: rmse 2.76370380964\n",
      "Errors of feature 3: rmse 2.63305652143\n",
      "Errors of feature 4: rmse 2.52531246606\n",
      "Errors of feature 5: rmse 2.43472295393\n",
      "Errors of feature 6: rmse 2.35712102047\n",
      "Errors of feature 7: rmse 2.28954508944\n",
      "Errors of feature 8: rmse 2.22985650076\n",
      "Errors of feature 9: rmse 2.17654462082\n",
      "Errors of feature 10: rmse 2.12849065966\n",
      "Errors of feature 11: rmse 2.08483350678\n",
      "Errors of feature 12: rmse 2.0448956447\n",
      "Errors of feature 13: rmse 2.00815435393\n",
      "Errors of feature 14: rmse 1.97418129335\n",
      "Errors of feature 15: rmse 1.94263109684\n",
      "Errors of feature 16: rmse 1.91322009778\n",
      "Errors of feature 17: rmse 1.8857124944\n",
      "Errors of feature 18: rmse 1.85990138792\n",
      "Errors of feature 19: rmse 1.83562284015\n",
      "Starting epoch: 1\n",
      "Errors of feature 0: rmse 1.68098797108\n",
      "Errors of feature 1: rmse 1.48814844864\n",
      "Errors of feature 2: rmse 1.40359079328\n",
      "Errors of feature 3: rmse 1.35536244543\n",
      "Errors of feature 4: rmse 1.32319390036\n",
      "Errors of feature 5: rmse 1.29966791493\n",
      "Errors of feature 6: rmse 1.28140949695\n",
      "Errors of feature 7: rmse 1.26664333603\n",
      "Errors of feature 8: rmse 1.25433641521\n",
      "Errors of feature 9: rmse 1.24384226871\n",
      "Errors of feature 10: rmse 1.23473261221\n",
      "Errors of feature 11: rmse 1.22670872205\n",
      "Errors of feature 12: rmse 1.21955769598\n"
     ]
    }
   ],
   "source": [
    "#NETFLIX\n",
    "\n",
    "#parameters\n",
    "k = 20\n",
    "n_epochs = 30\n",
    "#for k=40 takes approx 3min per epoch\n",
    "#for k=100 takes approx 11min per epoch\n",
    "#for k=200 takes approx 22min per epoch\n",
    "\n",
    "#remove/comment out the following four lines if you want to train your model even further\n",
    "movieFeature = np.zeros((k,1000)) + 0.1\n",
    "userFeature = np.zeros((k,10000)) + 0.1\n",
    "movieFeature_cache = []\n",
    "userFeature_cache = []\n",
    "\n",
    "error_cache = np.ones((k,)) * 5\n",
    "stop = False\n",
    "for epoch in range(n_epochs):\n",
    "    print(\"Starting epoch: \" + str(epoch))\n",
    "    for feature in range(k):\n",
    "        errors = []\n",
    "        movie_indices, user_indices = np.nonzero(X)\n",
    "        for i in range(len(movie_indices)):\n",
    "            movie = movie_indices[i]\n",
    "            user = user_indices[i]\n",
    "            error_squared = train_tikhonov(movie, user, feature, epoch==-1) ** 2\n",
    "            errors.append(error_squared)\n",
    "        rmserror = np.sqrt(np.mean(errors))\n",
    "        print(\"Errors of feature \" + str(feature) + \": rmse \" + str(rmserror))\n",
    "        #termination criteria: leave if training on this feature was worse than last epoch\n",
    "        if rmserror > error_cache[feature]:\n",
    "            stop = True\n",
    "            break\n",
    "        error_cache[feature] = rmserror\n",
    "    #cache the training data to recover fast from errors\n",
    "    movieFeature_cache.append(movieFeature)\n",
    "    userFeature_cache.append(userFeature)\n",
    "    if stop:\n",
    "        break\n",
    "\n",
    "#inspect if trained features have very high numbers (overfitted)\n",
    "print(movieFeature)\n",
    "print(userFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Output file\n",
    "\n",
    "#make sure to have X_a or have\n",
    "#movieFeature and userFeature trained\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "firstrow = True\n",
    "requested_y = []\n",
    "with open('sampleSubmission.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        if not firstrow:\n",
    "            numbers, value = parse(row)\n",
    "            requested_y.append(numbers)\n",
    "        else:\n",
    "            firstrow = False\n",
    "            \n",
    "        \n",
    "with open('submission-'+(time.strftime('%Y-%m-%d-%a-%Hh%Mmin'))+'-rmse-'+str(rmserror)+'.csv', 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerow(['ID','Prediction'])\n",
    "    for coord in requested_y:\n",
    "        r = coord[0]\n",
    "        c = coord[1]\n",
    "        #value = int(X_a[c-1, r-1]) #exchange this if desired\n",
    "        value = predictRating(c-1, r-1)\n",
    "        writer.writerow(['r%d_c%d'%(r, c) , str(value)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#backup SVD values (movieFeature & userFeature)\n",
    "import time\n",
    "np.savetxt('movieBackup'+(time.strftime('%Y-%m-%d-%a-%Hh%Mmin')+'.csv'), movieFeature, delimiter=\",\")\n",
    "np.savetxt(\"userBackup\"+(time.strftime('%Y-%m-%d-%a-%Hh%Mmin')+\".csv\"), userFeature, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let the system voice tell you that training has finished\n",
    "import os\n",
    "os.system('say \"Done\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
